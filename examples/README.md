# ğŸ“š LLM Guard Examples

This directory contains comprehensive examples demonstrating how to use LLM Guard in various scenarios. Each example is designed to be educational, practical, and ready to run.

## ğŸš€ Quick Start

If you're new to LLM Guard, start here:

### 1. **[quick_start.py](quick_start.py)** - Installation & Basic Usage
```bash
python examples/quick_start.py
```
- âœ… Verify installation
- ğŸ§ª Test basic functionality  
- ğŸ” Run safety detection tests
- ğŸ”’ Test PII redaction
- ğŸ“Š Perfect for first-time users

## ğŸ“– Comprehensive Examples

### 2. **[comprehensive_demo.py](comprehensive_demo.py)** - Full Feature Showcase
```bash
python examples/comprehensive_demo.py
```
- ğŸ›¡ï¸ Multi-category safety detection
- ğŸ”’ PII detection and redaction
- âš™ï¸ Custom rule creation
- ğŸ“ˆ Performance metrics
- ğŸ“ Comprehensive logging

### 3. **[basic_integration.py](basic_integration.py)** - Real-World Integration
```bash
python examples/basic_integration.py
```
- ğŸ¤– Complete chatbot example
- ğŸ”„ Input/output safety pipeline
- ğŸ“Š Safety statistics tracking
- ğŸ’¡ Production-ready patterns
- ğŸ—ï¸ Architecture best practices

### 4. **[custom_rules_demo.py](custom_rules_demo.py)** - Advanced Customization
```bash
python examples/custom_rules_demo.py
```
- ğŸ¢ Business-specific rules
- ğŸ›¡ï¸ Content moderation
- ğŸ“ Educational content filtering
- âš–ï¸ Rule priorities
- ğŸ”„ Dynamic rule management

## ğŸ“‹ Example Overview

| Example | Purpose | Complexity | Best For |
|---------|---------|------------|----------|
| `quick_start.py` | Getting started & verification | â­ Beginner | New users, testing installation |
| `comprehensive_demo.py` | Feature showcase | â­â­ Intermediate | Understanding all capabilities |
| `basic_integration.py` | Real integration patterns | â­â­â­ Advanced | Production implementation |
| `custom_rules_demo.py` | Advanced customization | â­â­â­ Expert | Domain-specific requirements |

## ğŸ¯ Use Case Examples

### For Chatbots & Conversational AI
- **Start with**: `basic_integration.py`
- **Learn**: Input validation, response filtering, conversation safety

### For Content Moderation
- **Start with**: `custom_rules_demo.py`
- **Learn**: Custom rules, content filtering, moderation workflows

### For Educational Platforms
- **Start with**: `custom_rules_demo.py` (educational section)
- **Learn**: Age-appropriate filtering, academic integrity

### For Business Applications
- **Start with**: `custom_rules_demo.py` (business section)
- **Learn**: Competitor mentions, internal data protection

## ğŸ”§ Running the Examples

### Prerequisites
```bash
pip install llm-guard
```

### Run Individual Examples
```bash
# Quick verification
python examples/quick_start.py

# Full feature demo
python examples/comprehensive_demo.py

# Integration example
python examples/basic_integration.py

# Custom rules demo
python examples/custom_rules_demo.py
```

### Run All Examples
```bash
# From the repository root
for example in examples/*.py; do
    echo "Running $example..."
    python "$example"
    echo "---"
done
```

## ğŸ“Š Expected Output

Each example provides:
- âœ… **Clear status indicators** (âœ… SAFE, âŒ BLOCKED, ğŸš© FLAGGED)
- â±ï¸ **Performance metrics** (latency measurements)
- ğŸ“ **Detailed explanations** of what's being tested
- ğŸ¯ **Practical insights** for your implementation

## ğŸ› ï¸ Customization

### Modify Examples for Your Use Case

1. **Change test inputs**: Edit the `test_cases` arrays in any example
2. **Add custom rules**: Follow patterns in `custom_rules_demo.py`
3. **Adjust thresholds**: Modify SafetyGuard initialization parameters
4. **Enable logging**: Set `log_file` parameter for detailed logs

### Example Customization
```python
# Customize for your domain
guard = SafetyGuard(
    log_file="my_app_safety.log",
    metrics_enabled=True,
    toxicity_threshold=0.8,  # Adjust sensitivity
    pii_detection_enabled=True
)

# Add your business rules
guard.add_custom_rule(
    name="my_custom_rule",
    pattern=r"your_pattern_here",
    action="block",
    message="Custom rule triggered"
)
```

## ğŸ› Troubleshooting

### Common Issues

1. **Import Error**: Ensure LLM Guard is installed: `pip install llm-guard`
2. **Permission Error**: Check file permissions for log files
3. **Performance Issues**: Reduce test cases or disable logging for faster execution

### Getting Help

- ğŸ“– Check the main [README](../README.md) for installation help
- ğŸ› Report issues on [GitHub Issues](https://github.com/juyterman1000/llm-safety/issues)
- ğŸ’¬ Join discussions on [GitHub Discussions](https://github.com/juyterman1000/llm-safety/discussions)

## ğŸš€ Next Steps

After running these examples:

1. **Integrate into your app**: Use patterns from `basic_integration.py`
2. **Create custom rules**: Follow `custom_rules_demo.py` patterns
3. **Monitor performance**: Implement metrics tracking
4. **Scale up**: Consider batch processing for high-volume applications

## ğŸ“„ License

These examples are part of LLM Guard and are licensed under the MIT License.

---

**Ready to make your LLM applications safer?** Start with `quick_start.py` and work your way through the examples! ğŸ›¡ï¸
